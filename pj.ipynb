{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label\n",
       "0  Go until jurong point, crazy.. Available only ...      0\n",
       "1                    Ok lar... Joking wif u oni...\\n      0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3  U dun say so early hor... U c already then say...      0\n",
       "4  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "data=pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms      0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       False\n",
      "1       False\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "5569    False\n",
      "5570    False\n",
      "5571    False\n",
      "5572    False\n",
      "5573    False\n",
      "Length: 5574, dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.duplicated())\n",
    "data[data.duplicated()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace = True,keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    sms  label\n",
      "0     Go until jurong point, crazy.. Available only ...      0\n",
      "1                       Ok lar... Joking wif u oni...\\n      0\n",
      "2     Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
      "3     U dun say so early hor... U c already then say...      0\n",
      "4     Nah I don't think he goes to usf, he lives aro...      0\n",
      "...                                                 ...    ...\n",
      "5166  This is the 2nd time we have tried 2 contact u...      1\n",
      "5167             Will Ã¼ b going to esplanade fr home?\\n      0\n",
      "5168  Pity, * was in mood for that. So...any other s...      0\n",
      "5169  The guy did some bitching but I acted like i'd...      0\n",
      "5170                       Rofl. Its true to its name\\n      0\n",
      "\n",
      "[5171 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "data.reset_index(inplace = True,drop=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lowercase_sms']=data['sms'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>lowercase_sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...      0   \n",
       "1                    Ok lar... Joking wif u oni...\\n      0   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3  U dun say so early hor... U c already then say...      0   \n",
       "4  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                       lowercase_sms  \n",
       "0  go until jurong point, crazy.. available only ...  \n",
       "1                    ok lar... joking wif u oni...\\n  \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3  u dun say so early hor... u c already then say...  \n",
       "4  nah i don't think he goes to usf, he lives aro...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\VB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT_TO_REMOVE = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('','',PUNCT_TO_REMOVE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"punct_removed\"] = data[\"lowercase_sms\"].apply(lambda text: remove_punctuation(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>lowercase_sms</th>\n",
       "      <th>punct_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...\\n</td>\n",
       "      <td>ok lar joking wif u oni\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...      0   \n",
       "1                    Ok lar... Joking wif u oni...\\n      0   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3  U dun say so early hor... U c already then say...      0   \n",
       "4  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                       lowercase_sms  \\\n",
       "0  go until jurong point, crazy.. available only ...   \n",
       "1                    ok lar... joking wif u oni...\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3  u dun say so early hor... u c already then say...   \n",
       "4  nah i don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       punct_removed  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                          ok lar joking wif u oni\\n  \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "3      u dun say so early hor u c already then say\\n  \n",
       "4  nah i dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\VB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join(word for word in str(text).split() if word not in STOPWORDS)\n",
    "data[\"stopwords_removed\"] = data[\"punct_removed\"].apply(lambda text: remove_stopwords(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>lowercase_sms</th>\n",
       "      <th>punct_removed</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...\\n</td>\n",
       "      <td>ok lar joking wif u oni\\n</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say\\n</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...      0   \n",
       "1                    Ok lar... Joking wif u oni...\\n      0   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3  U dun say so early hor... U c already then say...      0   \n",
       "4  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                       lowercase_sms  \\\n",
       "0  go until jurong point, crazy.. available only ...   \n",
       "1                    ok lar... joking wif u oni...\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3  u dun say so early hor... u c already then say...   \n",
       "4  nah i don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       punct_removed  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                          ok lar joking wif u oni\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      u dun say so early hor u c already then say\\n   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                   stopwords_removed  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3                u dun say early hor u c already say  \n",
       "4        nah dont think goes usf lives around though  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\VB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\VB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data['stopwords_removed'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>lowercase_sms</th>\n",
       "      <th>punct_removed</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...\\n</td>\n",
       "      <td>ok lar joking wif u oni\\n</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say\\n</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...      0   \n",
       "1                    Ok lar... Joking wif u oni...\\n      0   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3  U dun say so early hor... U c already then say...      0   \n",
       "4  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                       lowercase_sms  \\\n",
       "0  go until jurong point, crazy.. available only ...   \n",
       "1                    ok lar... joking wif u oni...\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3  u dun say so early hor... u c already then say...   \n",
       "4  nah i don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       punct_removed  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                          ok lar joking wif u oni\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      u dun say so early hor u c already then say\\n   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  go jurong point crazy available bugis n great ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "3                u dun say early hor u c already say   \n",
       "4        nah dont think goes usf lives around though   \n",
       "\n",
       "                                              tokens  \n",
       "0  [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                     [ok, lar, joking, wif, u, oni]  \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, early, hor, u, c, already, say]  \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tokens(tokens):\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stemmed_tokens'] = data['tokens'].apply(stem_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>lowercase_sms</th>\n",
       "      <th>punct_removed</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...\\n</td>\n",
       "      <td>ok lar joking wif u oni\\n</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say\\n</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...      0   \n",
       "1                    Ok lar... Joking wif u oni...\\n      0   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3  U dun say so early hor... U c already then say...      0   \n",
       "4  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                       lowercase_sms  \\\n",
       "0  go until jurong point, crazy.. available only ...   \n",
       "1                    ok lar... joking wif u oni...\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3  u dun say so early hor... u c already then say...   \n",
       "4  nah i don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       punct_removed  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                          ok lar joking wif u oni\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      u dun say so early hor u c already then say\\n   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  go jurong point crazy available bugis n great ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "3                u dun say early hor u c already say   \n",
       "4        nah dont think goes usf lives around though   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                       [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\VB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    " nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokens(tokens):\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>lowercase_sms</th>\n",
       "      <th>punct_removed</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...\\n</td>\n",
       "      <td>ok lar joking wif u oni\\n</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say\\n</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...      0   \n",
       "1                    Ok lar... Joking wif u oni...\\n      0   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3  U dun say so early hor... U c already then say...      0   \n",
       "4  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                       lowercase_sms  \\\n",
       "0  go until jurong point, crazy.. available only ...   \n",
       "1                    ok lar... joking wif u oni...\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3  u dun say so early hor... u c already then say...   \n",
       "4  nah i don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       punct_removed  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                          ok lar joking wif u oni\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      u dun say so early hor u c already then say\\n   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  go jurong point crazy available bugis n great ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "3                u dun say early hor u c already say   \n",
       "4        nah dont think goes usf lives around though   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                   lemmatized_tokens  \n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...  \n",
       "1                       [ok, lar, joke, wif, u, oni]  \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...  \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]  \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['lemmatized_tokens'] = data['stemmed_tokens'].apply(lemmatize_tokens)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\VB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag_tokens(tokens):\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    return pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pos_tags'] = data['lemmatized_tokens'].apply(pos_tag_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>lowercase_sms</th>\n",
       "      <th>punct_removed</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[(go, VB), (jurong, JJ), (point, NN), (crazi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...\\n</td>\n",
       "      <td>ok lar joking wif u oni\\n</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[(ok, JJ), (lar, JJ), (joke, NN), (wif, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[(free, JJ), (entri, NN), (2, CD), (wkli, NN),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say\\n</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[(u, JJ), (dun, NNS), (say, VBP), (earli, JJ),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[(nah, JJ), (dont, NN), (think, VBP), (goe, JJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...      0   \n",
       "1                    Ok lar... Joking wif u oni...\\n      0   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3  U dun say so early hor... U c already then say...      0   \n",
       "4  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                       lowercase_sms  \\\n",
       "0  go until jurong point, crazy.. available only ...   \n",
       "1                    ok lar... joking wif u oni...\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3  u dun say so early hor... u c already then say...   \n",
       "4  nah i don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       punct_removed  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                          ok lar joking wif u oni\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      u dun say so early hor u c already then say\\n   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  go jurong point crazy available bugis n great ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "3                u dun say early hor u c already say   \n",
       "4        nah dont think goes usf lives around though   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  [(go, VB), (jurong, JJ), (point, NN), (crazi, ...  \n",
       "1  [(ok, JJ), (lar, JJ), (joke, NN), (wif, NN), (...  \n",
       "2  [(free, JJ), (entri, NN), (2, CD), (wkli, NN),...  \n",
       "3  [(u, JJ), (dun, NNS), (say, VBP), (earli, JJ),...  \n",
       "4  [(nah, JJ), (dont, NN), (think, VBP), (goe, JJ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = le.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>lowercase_sms</th>\n",
       "      <th>punct_removed</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[(go, VB), (jurong, JJ), (point, NN), (crazi, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...\\n</td>\n",
       "      <td>ok lar joking wif u oni\\n</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[(ok, JJ), (lar, JJ), (joke, NN), (wif, NN), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[(free, JJ), (entri, NN), (2, CD), (wkli, NN),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say\\n</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[(u, JJ), (dun, NNS), (say, VBP), (earli, JJ),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[(nah, JJ), (dont, NN), (think, VBP), (goe, JJ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...      0   \n",
       "1                    Ok lar... Joking wif u oni...\\n      0   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3  U dun say so early hor... U c already then say...      0   \n",
       "4  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                       lowercase_sms  \\\n",
       "0  go until jurong point, crazy.. available only ...   \n",
       "1                    ok lar... joking wif u oni...\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3  u dun say so early hor... u c already then say...   \n",
       "4  nah i don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       punct_removed  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                          ok lar joking wif u oni\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      u dun say so early hor u c already then say\\n   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  go jurong point crazy available bugis n great ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "3                u dun say early hor u c already say   \n",
       "4        nah dont think goes usf lives around though   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  [(go, VB), (jurong, JJ), (point, NN), (crazi, ...  \n",
       "1  [(ok, JJ), (lar, JJ), (joke, NN), (wif, NN), (...  \n",
       "2  [(free, JJ), (entri, NN), (2, CD), (wkli, NN),...  \n",
       "3  [(u, JJ), (dun, NNS), (say, VBP), (earli, JJ),...  \n",
       "4  [(nah, JJ), (dont, NN), (think, VBP), (goe, JJ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 43426 stored elements and shape (5171, 9437)>\n",
      "  Coords\tValues\n",
      "  (0, 3791)\t1\n",
      "  (0, 4687)\t1\n",
      "  (0, 6433)\t1\n",
      "  (0, 2497)\t1\n",
      "  (0, 1414)\t1\n",
      "  (0, 1881)\t1\n",
      "  (0, 3888)\t1\n",
      "  (0, 9184)\t1\n",
      "  (0, 4847)\t1\n",
      "  (0, 1879)\t1\n",
      "  (0, 2214)\t1\n",
      "  (0, 3848)\t1\n",
      "  (0, 1181)\t1\n",
      "  (0, 8947)\t1\n",
      "  (1, 5995)\t1\n",
      "  (1, 4886)\t1\n",
      "  (1, 4655)\t1\n",
      "  (1, 9079)\t1\n",
      "  (1, 6027)\t1\n",
      "  (2, 3577)\t1\n",
      "  (2, 3160)\t2\n",
      "  (2, 9136)\t1\n",
      "  (2, 2330)\t1\n",
      "  (2, 9093)\t1\n",
      "  (2, 3296)\t2\n",
      "  :\t:\n",
      "  (5167, 4188)\t1\n",
      "  (5167, 3810)\t1\n",
      "  (5167, 3564)\t1\n",
      "  (5167, 3188)\t1\n",
      "  (5168, 5566)\t1\n",
      "  (5168, 6359)\t1\n",
      "  (5168, 7611)\t1\n",
      "  (5168, 7986)\t1\n",
      "  (5169, 3577)\t1\n",
      "  (5169, 4343)\t1\n",
      "  (5169, 5000)\t1\n",
      "  (5169, 8997)\t1\n",
      "  (5169, 5777)\t1\n",
      "  (5169, 8731)\t1\n",
      "  (5169, 7636)\t1\n",
      "  (5169, 3103)\t1\n",
      "  (5169, 3701)\t1\n",
      "  (5169, 1916)\t1\n",
      "  (5169, 4480)\t1\n",
      "  (5169, 3950)\t1\n",
      "  (5169, 999)\t1\n",
      "  (5169, 1665)\t1\n",
      "  (5170, 5688)\t1\n",
      "  (5170, 8538)\t1\n",
      "  (5170, 7052)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(data['stopwords_removed'])\n",
    "y = data['label']\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data (3619, 9437) (3619,)\n",
      "Testing Data (1552, 9437) (1552,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1353\n",
      "           1       0.99      0.83      0.90       199\n",
      "\n",
      "    accuracy                           0.98      1552\n",
      "   macro avg       0.98      0.91      0.94      1552\n",
      "weighted avg       0.98      0.98      0.98      1552\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics \n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "print ('Training Data' , x_train.shape,y_train.shape)\n",
    "print ('Testing Data', x_test.shape,y_test.shape)\n",
    "\n",
    "model = LogisticRegression()\n",
    "clf = model.fit(x_train,y_train)\n",
    "prediction = model.predict(x_test)\n",
    "print(metrics.classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 43426 stored elements and shape (5171, 9437)>\n",
      "  Coords\tValues\n",
      "  (0, 3791)\t1\n",
      "  (0, 4687)\t1\n",
      "  (0, 6433)\t1\n",
      "  (0, 2497)\t1\n",
      "  (0, 1414)\t1\n",
      "  (0, 1881)\t1\n",
      "  (0, 3888)\t1\n",
      "  (0, 9184)\t1\n",
      "  (0, 4847)\t1\n",
      "  (0, 1879)\t1\n",
      "  (0, 2214)\t1\n",
      "  (0, 3848)\t1\n",
      "  (0, 1181)\t1\n",
      "  (0, 8947)\t1\n",
      "  (1, 5995)\t1\n",
      "  (1, 4886)\t1\n",
      "  (1, 4655)\t1\n",
      "  (1, 9079)\t1\n",
      "  (1, 6027)\t1\n",
      "  (2, 3577)\t1\n",
      "  (2, 3160)\t2\n",
      "  (2, 9136)\t1\n",
      "  (2, 2330)\t1\n",
      "  (2, 9093)\t1\n",
      "  (2, 3296)\t2\n",
      "  :\t:\n",
      "  (5167, 4188)\t1\n",
      "  (5167, 3810)\t1\n",
      "  (5167, 3564)\t1\n",
      "  (5167, 3188)\t1\n",
      "  (5168, 5566)\t1\n",
      "  (5168, 6359)\t1\n",
      "  (5168, 7611)\t1\n",
      "  (5168, 7986)\t1\n",
      "  (5169, 3577)\t1\n",
      "  (5169, 4343)\t1\n",
      "  (5169, 5000)\t1\n",
      "  (5169, 8997)\t1\n",
      "  (5169, 5777)\t1\n",
      "  (5169, 8731)\t1\n",
      "  (5169, 7636)\t1\n",
      "  (5169, 3103)\t1\n",
      "  (5169, 3701)\t1\n",
      "  (5169, 1916)\t1\n",
      "  (5169, 4480)\t1\n",
      "  (5169, 3950)\t1\n",
      "  (5169, 999)\t1\n",
      "  (5169, 1665)\t1\n",
      "  (5170, 5688)\t1\n",
      "  (5170, 8538)\t1\n",
      "  (5170, 7052)\t1\n",
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 43426 stored elements and shape (5171, 9437)>\n",
      "  Coords\tValues\n",
      "  (0, 3791)\t0.15604425261688118\n",
      "  (0, 4687)\t0.3443770206465341\n",
      "  (0, 6433)\t0.2687237400923966\n",
      "  (0, 2497)\t0.26604142864786673\n",
      "  (0, 1414)\t0.26604142864786673\n",
      "  (0, 1881)\t0.2904805361231674\n",
      "  (0, 3888)\t0.19346921273096365\n",
      "  (0, 9184)\t0.24776858267805021\n",
      "  (0, 4847)\t0.2904805361231674\n",
      "  (0, 1879)\t0.3286133094631002\n",
      "  (0, 2214)\t0.2904805361231674\n",
      "  (0, 3848)\t0.1612794558535063\n",
      "  (0, 1181)\t0.3443770206465341\n",
      "  (0, 8947)\t0.19681562958845308\n",
      "  (1, 5995)\t0.27827264001570345\n",
      "  (1, 4886)\t0.40674103719650717\n",
      "  (1, 4655)\t0.5230989243093604\n",
      "  (1, 9079)\t0.4302474447408418\n",
      "  (1, 6027)\t0.5462423621062051\n",
      "  (2, 3577)\t0.1130668664480147\n",
      "  (2, 3160)\t0.3508857268813137\n",
      "  (2, 9136)\t0.1924878028735826\n",
      "  (2, 2330)\t0.1924878028735826\n",
      "  (2, 9093)\t0.14770414004532098\n",
      "  (2, 3296)\t0.4704554083299156\n",
      "  :\t:\n",
      "  (5167, 4188)\t0.3679601168327961\n",
      "  (5167, 3810)\t0.36379105850972265\n",
      "  (5167, 3564)\t0.5617957262077592\n",
      "  (5167, 3188)\t0.6454819751034625\n",
      "  (5168, 5566)\t0.45130908131455416\n",
      "  (5168, 6359)\t0.5152087321733504\n",
      "  (5168, 7611)\t0.5152087321733504\n",
      "  (5168, 7986)\t0.5152087321733504\n",
      "  (5169, 3577)\t0.17686760404977311\n",
      "  (5169, 4343)\t0.2554667845310558\n",
      "  (5169, 5000)\t0.1732705029307577\n",
      "  (5169, 8997)\t0.20982982777545844\n",
      "  (5169, 5777)\t0.2259864343867017\n",
      "  (5169, 8731)\t0.23104980423296034\n",
      "  (5169, 7636)\t0.22147372507589522\n",
      "  (5169, 3103)\t0.2630405219531142\n",
      "  (5169, 3701)\t0.29714450416636623\n",
      "  (5169, 1916)\t0.3054804748681181\n",
      "  (5169, 4480)\t0.3103732467406318\n",
      "  (5169, 3950)\t0.2647362899850345\n",
      "  (5169, 999)\t0.3511174316237154\n",
      "  (5169, 1665)\t0.3679606744997525\n",
      "  (5170, 5688)\t0.49120268365249836\n",
      "  (5170, 8538)\t0.542850436188723\n",
      "  (5170, 7052)\t0.6811999174268131\n",
      "Training Data: (3619, 9437) (3619,)\n",
      "Testing Data:  (1552, 9437) (1552,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "BOG = CountVectorizer()\n",
    "x = BOG.fit_transform(data['stopwords_removed'])\n",
    "y = data['label']\n",
    "print(x)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "x = tfidf.fit_transform(data['stopwords_removed'])\n",
    "y = data['label']\n",
    "print(x)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)\n",
    "print('Training Data:',x_train.shape, y_train.shape)\n",
    "print('Testing Data: ',x_test.shape, y_test.shape)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "models = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'LinearSVC': LinearSVC(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'MLPClassifier': MLPClassifier(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
    "    'BaggingClassifier': BaggingClassifier(),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'SGDClassifier': SGDClassifier()\n",
    "}\n",
    "\n",
    "for i in range(len(models)):\n",
    "    model =list(models.values())[i]\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\VB\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = sia.polarity_scores(text)\n",
    "    return sentiment_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sms</th>\n",
       "      <th>label</th>\n",
       "      <th>lowercase_sms</th>\n",
       "      <th>punct_removed</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[go, jurong, point, crazi, avail, bugi, n, gre...</td>\n",
       "      <td>[(go, VB), (jurong, JJ), (point, NN), (crazi, ...</td>\n",
       "      <td>{'neg': 0.13, 'neu': 0.649, 'pos': 0.222, 'com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>ok lar... joking wif u oni...\\n</td>\n",
       "      <td>ok lar joking wif u oni\\n</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joke, wif, u, oni]</td>\n",
       "      <td>[(ok, JJ), (lar, JJ), (joke, NN), (wif, NN), (...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entri, 2, wkli, comp, win, fa, cup, fin...</td>\n",
       "      <td>[(free, JJ), (entri, NN), (2, CD), (wkli, NN),...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say\\n</td>\n",
       "      <td>u dun say early hor u c already say</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[u, dun, say, earli, hor, u, c, alreadi, say]</td>\n",
       "      <td>[(u, JJ), (dun, NNS), (say, VBP), (earli, JJ),...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[nah, dont, think, goe, usf, live, around, tho...</td>\n",
       "      <td>[(nah, JJ), (dont, NN), (think, VBP), (goe, JJ...</td>\n",
       "      <td>{'neg': 0.167, 'neu': 0.833, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 sms  label  \\\n",
       "0  Go until jurong point, crazy.. Available only ...      0   \n",
       "1                    Ok lar... Joking wif u oni...\\n      0   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1   \n",
       "3  U dun say so early hor... U c already then say...      0   \n",
       "4  Nah I don't think he goes to usf, he lives aro...      0   \n",
       "\n",
       "                                       lowercase_sms  \\\n",
       "0  go until jurong point, crazy.. available only ...   \n",
       "1                    ok lar... joking wif u oni...\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3  u dun say so early hor... u c already then say...   \n",
       "4  nah i don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                       punct_removed  \\\n",
       "0  go until jurong point crazy available only in ...   \n",
       "1                          ok lar joking wif u oni\\n   \n",
       "2  free entry in 2 a wkly comp to win fa cup fina...   \n",
       "3      u dun say so early hor u c already then say\\n   \n",
       "4  nah i dont think he goes to usf he lives aroun...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  go jurong point crazy available bugis n great ...   \n",
       "1                            ok lar joking wif u oni   \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...   \n",
       "3                u dun say early hor u c already say   \n",
       "4        nah dont think goes usf lives around though   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                     [ok, lar, joking, wif, u, oni]   \n",
       "2  [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, early, hor, u, c, already, say]   \n",
       "4  [nah, dont, think, goes, usf, lives, around, t...   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [go, jurong, point, crazi, avail, bugi, n, gre...   \n",
       "1                       [ok, lar, joke, wif, u, oni]   \n",
       "2  [free, entri, 2, wkli, comp, win, fa, cup, fin...   \n",
       "3      [u, dun, say, earli, hor, u, c, alreadi, say]   \n",
       "4  [nah, dont, think, goe, usf, live, around, tho...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [(go, VB), (jurong, JJ), (point, NN), (crazi, ...   \n",
       "1  [(ok, JJ), (lar, JJ), (joke, NN), (wif, NN), (...   \n",
       "2  [(free, JJ), (entri, NN), (2, CD), (wkli, NN),...   \n",
       "3  [(u, JJ), (dun, NNS), (say, VBP), (earli, JJ),...   \n",
       "4  [(nah, JJ), (dont, NN), (think, VBP), (goe, JJ...   \n",
       "\n",
       "                                              Result  \n",
       "0  {'neg': 0.13, 'neu': 0.649, 'pos': 0.222, 'com...  \n",
       "1  {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...  \n",
       "2  {'neg': 0.0, 'neu': 0.738, 'pos': 0.262, 'comp...  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "4  {'neg': 0.167, 'neu': 0.833, 'pos': 0.0, 'comp...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Result'] = np.array([sentiment_analysis(stopwords_removed) for stopwords_removed in data['stopwords_removed'] ])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "s = \" yes \"\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
